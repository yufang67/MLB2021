[LightGBM] [Warning] bagging_fraction is set=0.6105639383613035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6105639383613035
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10
[LightGBM] [Warning] feature_fraction is set=0.696714966055408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.696714966055408
[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[2210]	valid_0's l2: 83.9846
[I 2021-07-30 09:12:13,780] Finished trial#0 with value: 6.181596507402616 with parameters: {'objective': 'mse', 'learning_rate': 0.00023772791036907518, 'n_estimators': 2210, 'max_depth': 5, 'num_leaves': 28829, 'max_bin': 44, 'feature_fraction': 0.696714966055408, 'bagging_fraction': 0.6105639383613035, 'bagging_freq': 97, 'min_sum_hessian_in_leaf': 10, 'reg_alpha': 0.0012410390849908418, 'reg_lambda': 0.0006043079991608977}. Best is trial#0 with value: 6.181596507402616.
[LightGBM] [Warning] bagging_fraction is set=0.5379070185656657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5379070185656657
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4
[LightGBM] [Warning] feature_fraction is set=0.49285046879922945, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49285046879922945
[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[589]	valid_0's l1: 3.99153
[I 2021-07-30 09:12:19,168] Finished trial#1 with value: 3.9915347805288155 with parameters: {'objective': 'mae', 'learning_rate': 0.006533992434427841, 'n_estimators': 4600, 'max_depth': 4, 'num_leaves': 47767, 'max_bin': 181, 'feature_fraction': 0.49285046879922945, 'bagging_fraction': 0.5379070185656657, 'bagging_freq': 25, 'min_sum_hessian_in_leaf': 4, 'reg_alpha': 0.00020313978295592212, 'reg_lambda': 0.0030905822167834576}. Best is trial#1 with value: 3.9915347805288155.
[LightGBM] [Warning] bagging_fraction is set=0.7160574257188062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7160574257188062
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.5225037502665765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5225037502665765
[LightGBM] [Warning] bagging_freq is set=82, subsample_freq=0 will be ignored. Current value: bagging_freq=82
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[3693]	valid_0's huber: 5.022
[I 2021-07-30 09:13:59,640] Finished trial#2 with value: 6.020853321749474 with parameters: {'objective': 'huber', 'learning_rate': 0.0010767035241822623, 'n_estimators': 3693, 'max_depth': 8, 'num_leaves': 42954, 'max_bin': 223, 'feature_fraction': 0.5225037502665765, 'bagging_fraction': 0.7160574257188062, 'bagging_freq': 82, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 3.982914643845331e-05, 'reg_lambda': 0.006027413612592597}. Best is trial#1 with value: 3.9915347805288155.
[LightGBM] [Warning] bagging_fraction is set=0.36862634955975326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.36862634955975326
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.49341062610206254, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49341062610206254
[LightGBM] [Warning] bagging_freq is set=79, subsample_freq=0 will be ignored. Current value: bagging_freq=79
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[29]	valid_0's l2: 66.7816
[I 2021-07-30 09:14:06,250] Finished trial#3 with value: 5.124864459593962 with parameters: {'objective': 'mse', 'learning_rate': 0.05790221348622845, 'n_estimators': 1626, 'max_depth': 12, 'num_leaves': 4867, 'max_bin': 155, 'feature_fraction': 0.49341062610206254, 'bagging_fraction': 0.36862634955975326, 'bagging_freq': 79, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.0004514349962110303, 'reg_lambda': 0.021066226911246155}. Best is trial#1 with value: 3.9915347805288155.
[LightGBM] [Warning] bagging_fraction is set=0.12576210091144172, subsample=1.0 will be ignored. Current value: bagging_fraction=0.12576210091144172
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.3036494804001454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3036494804001454
[LightGBM] [Warning] bagging_freq is set=48, subsample_freq=0 will be ignored. Current value: bagging_freq=48
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[2908]	valid_0's l2: 68.1539
[I 2021-07-30 09:19:12,939] Finished trial#4 with value: 5.397021076466717 with parameters: {'objective': 'mse', 'learning_rate': 0.0004890013179702633, 'n_estimators': 2908, 'max_depth': 15, 'num_leaves': 88980, 'max_bin': 233, 'feature_fraction': 0.3036494804001454, 'bagging_fraction': 0.12576210091144172, 'bagging_freq': 48, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.00022195671660338426, 'reg_lambda': 0.0008935083008152089}. Best is trial#1 with value: 3.9915347805288155.
[LightGBM] [Warning] bagging_fraction is set=0.5943382136044963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5943382136044963
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.5545910178252824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5545910178252824
[LightGBM] [Warning] bagging_freq is set=59, subsample_freq=0 will be ignored. Current value: bagging_freq=59
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[3624]	valid_0's l2: 74.8925
[I 2021-07-30 09:20:03,331] Finished trial#5 with value: 5.744967580108196 with parameters: {'objective': 'mse', 'learning_rate': 0.0002261907536237825, 'n_estimators': 3624, 'max_depth': 6, 'num_leaves': 18797, 'max_bin': 166, 'feature_fraction': 0.5545910178252824, 'bagging_fraction': 0.5943382136044963, 'bagging_freq': 59, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 1.8974913110114113e-05, 'reg_lambda': 0.0047331661959267805}. Best is trial#1 with value: 3.9915347805288155.
[LightGBM] [Warning] bagging_fraction is set=0.14728289315660928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.14728289315660928
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.6414588672768913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6414588672768913
[LightGBM] [Warning] bagging_freq is set=56, subsample_freq=0 will be ignored. Current value: bagging_freq=56
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[1323]	valid_0's huber: 6.50079
[I 2021-07-30 09:21:43,435] Finished trial#6 with value: 7.667938307980224 with parameters: {'objective': 'huber', 'learning_rate': 0.00023297073413268074, 'n_estimators': 1323, 'max_depth': 14, 'num_leaves': 70481, 'max_bin': 70, 'feature_fraction': 0.6414588672768913, 'bagging_fraction': 0.14728289315660928, 'bagging_freq': 56, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.00014680440025689197, 'reg_lambda': 7.190076263157983e-05}. Best is trial#1 with value: 3.9915347805288155.
[LightGBM] [Warning] bagging_fraction is set=0.25102680273515626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.25102680273515626
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.5092672416930584, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5092672416930584
[LightGBM] [Warning] bagging_freq is set=68, subsample_freq=0 will be ignored. Current value: bagging_freq=68
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[97]	valid_0's l2: 66.1852
[I 2021-07-30 09:21:55,035] Finished trial#7 with value: 5.102556357061307 with parameters: {'objective': 'mse', 'learning_rate': 0.017293054313833333, 'n_estimators': 4736, 'max_depth': 17, 'num_leaves': 1535, 'max_bin': 35, 'feature_fraction': 0.5092672416930584, 'bagging_fraction': 0.25102680273515626, 'bagging_freq': 68, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.0273934659084166, 'reg_lambda': 0.0035370938023045564}. Best is trial#1 with value: 3.9915347805288155.
[LightGBM] [Warning] bagging_fraction is set=0.3582376256823424, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3582376256823424
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.9005936589169252, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9005936589169252
[LightGBM] [Warning] bagging_freq is set=45, subsample_freq=0 will be ignored. Current value: bagging_freq=45
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[302]	valid_0's l1: 3.95083
[I 2021-07-30 09:23:40,428] Finished trial#8 with value: 3.9508289232177582 with parameters: {'objective': 'mae', 'learning_rate': 0.004197145832807719, 'n_estimators': 1227, 'max_depth': 15, 'num_leaves': 70584, 'max_bin': 116, 'feature_fraction': 0.9005936589169252, 'bagging_fraction': 0.3582376256823424, 'bagging_freq': 45, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.006815121975525883, 'reg_lambda': 0.0009827358112703783}. Best is trial#8 with value: 3.9508289232177582.
[LightGBM] [Warning] bagging_fraction is set=0.6782350467431314, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6782350467431314
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=5, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=5
[LightGBM] [Warning] feature_fraction is set=0.2859246496736078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2859246496736078
[LightGBM] [Warning] bagging_freq is set=28, subsample_freq=0 will be ignored. Current value: bagging_freq=28
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[556]	valid_0's l1: 4.07028
[I 2021-07-30 09:25:13,050] Finished trial#9 with value: 4.07028460456125 with parameters: {'objective': 'mae', 'learning_rate': 0.0019052133761106415, 'n_estimators': 556, 'max_depth': 13, 'num_leaves': 66510, 'max_bin': 140, 'feature_fraction': 0.2859246496736078, 'bagging_fraction': 0.6782350467431314, 'bagging_freq': 28, 'min_sum_hessian_in_leaf': 5, 'reg_alpha': 0.05678099389043291, 'reg_lambda': 0.0001151538590225325}. Best is trial#8 with value: 3.9508289232177582.
[LightGBM] [Warning] bagging_fraction is set=0.9136859218748747, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9136859218748747
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.9791891193485872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9791891193485872
[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[166]	valid_0's l1: 3.94656
[I 2021-07-30 09:32:02,310] Finished trial#10 with value: 3.9465581166476316 with parameters: {'objective': 'mae', 'learning_rate': 0.007376059186632639, 'n_estimators': 327, 'max_depth': 20, 'num_leaves': 123366, 'max_bin': 90, 'feature_fraction': 0.9791891193485872, 'bagging_fraction': 0.9136859218748747, 'bagging_freq': 3, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.006063329830515547, 'reg_lambda': 1.4726962140388333e-05}. Best is trial#10 with value: 3.9465581166476316.
[LightGBM] [Warning] bagging_fraction is set=0.9992000950860199, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992000950860199
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.9919038900374022, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9919038900374022
[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[202]	valid_0's l1: 3.96008
[I 2021-07-30 09:38:15,215] Finished trial#11 with value: 3.960084440358128 with parameters: {'objective': 'mae', 'learning_rate': 0.005900635083653453, 'n_estimators': 205, 'max_depth': 20, 'num_leaves': 128223, 'max_bin': 97, 'feature_fraction': 0.9919038900374022, 'bagging_fraction': 0.9992000950860199, 'bagging_freq': 2, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.004558873829749178, 'reg_lambda': 1.3286216227236326e-05}. Best is trial#10 with value: 3.9465581166476316.
[LightGBM] [Warning] bagging_fraction is set=0.9362218966817153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9362218966817153
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4
[LightGBM] [Warning] feature_fraction is set=0.9947549497233015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9947549497233015
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[45]	valid_0's l1: 3.97486
[I 2021-07-30 09:41:50,499] Finished trial#12 with value: 3.974855238873616 with parameters: {'objective': 'mae', 'learning_rate': 0.027139157342909732, 'n_estimators': 893, 'max_depth': 20, 'num_leaves': 126361, 'max_bin': 104, 'feature_fraction': 0.9947549497233015, 'bagging_fraction': 0.9362218966817153, 'bagging_freq': 1, 'min_sum_hessian_in_leaf': 4, 'reg_alpha': 0.007011741295600003, 'reg_lambda': 0.0993890827293946}. Best is trial#10 with value: 3.9465581166476316.
[LightGBM] [Warning] bagging_fraction is set=0.4071697920823082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4071697920823082
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8587242356027502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8587242356027502
[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[204]	valid_0's l1: 3.95422
[I 2021-07-30 09:44:55,808] Finished trial#13 with value: 3.9542173133437712 with parameters: {'objective': 'mae', 'learning_rate': 0.006008673632528933, 'n_estimators': 354, 'max_depth': 17, 'num_leaves': 106078, 'max_bin': 103, 'feature_fraction': 0.8587242356027502, 'bagging_fraction': 0.4071697920823082, 'bagging_freq': 22, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.012382859397659294, 'reg_lambda': 3.44761632098798e-05}. Best is trial#10 with value: 3.9465581166476316.
[LightGBM] [Warning] bagging_fraction is set=0.8429533508898417, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8429533508898417
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4
[LightGBM] [Warning] feature_fraction is set=0.8311308475552666, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8311308475552666
[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[106]	valid_0's l1: 3.92131
[I 2021-07-30 09:45:11,400] Finished trial#14 with value: 3.9213052285135217 with parameters: {'objective': 'mae', 'learning_rate': 0.012512343169226989, 'n_estimators': 1731, 'max_depth': 10, 'num_leaves': 100682, 'max_bin': 11, 'feature_fraction': 0.8311308475552666, 'bagging_fraction': 0.8429533508898417, 'bagging_freq': 38, 'min_sum_hessian_in_leaf': 4, 'reg_alpha': 0.0019454785480839563, 'reg_lambda': 0.00020672869646529295}. Best is trial#14 with value: 3.9213052285135217.
[LightGBM] [Warning] bagging_fraction is set=0.8604076134482658, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8604076134482658
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4
[LightGBM] [Warning] feature_fraction is set=0.7945597028340633, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7945597028340633
[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[16]	valid_0's l1: 3.93698
[I 2021-07-30 09:45:16,678] Finished trial#15 with value: 3.9369819130357815 with parameters: {'objective': 'mae', 'learning_rate': 0.09982930189197521, 'n_estimators': 2094, 'max_depth': 9, 'num_leaves': 108550, 'max_bin': 14, 'feature_fraction': 0.7945597028340633, 'bagging_fraction': 0.8604076134482658, 'bagging_freq': 11, 'min_sum_hessian_in_leaf': 4, 'reg_alpha': 0.0015518479170004082, 'reg_lambda': 1.086271016379748e-05}. Best is trial#14 with value: 3.9213052285135217.
[LightGBM] [Warning] bagging_fraction is set=0.8142911509484303, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8142911509484303
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3
[LightGBM] [Warning] feature_fraction is set=0.803344350058488, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.803344350058488
[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[15]	valid_0's l1: 3.93039
[I 2021-07-30 09:45:21,918] Finished trial#16 with value: 3.9303930736881103 with parameters: {'objective': 'mae', 'learning_rate': 0.09383385670691768, 'n_estimators': 2061, 'max_depth': 9, 'num_leaves': 99818, 'max_bin': 13, 'feature_fraction': 0.803344350058488, 'bagging_fraction': 0.8142911509484303, 'bagging_freq': 14, 'min_sum_hessian_in_leaf': 3, 'reg_alpha': 0.0016393698539827447, 'reg_lambda': 0.00018242089465960034}. Best is trial#14 with value: 3.9213052285135217.
[LightGBM] [Warning] bagging_fraction is set=0.7959048675890306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7959048675890306
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.7200994385303694, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200994385303694
[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[978]	valid_0's huber: 3.05415
[I 2021-07-30 09:46:02,872] Finished trial#17 with value: 3.8094188519279575 with parameters: {'objective': 'huber', 'learning_rate': 0.02257705049780383, 'n_estimators': 2839, 'max_depth': 9, 'num_leaves': 90973, 'max_bin': 13, 'feature_fraction': 0.7200994385303694, 'bagging_fraction': 0.7959048675890306, 'bagging_freq': 36, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0020452698794901384, 'reg_lambda': 0.00021296331941350217}. Best is trial#17 with value: 3.8094188519279575.
[LightGBM] [Warning] bagging_fraction is set=0.7628505123292743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7628505123292743
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.7105246361635494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7105246361635494
[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[978]	valid_0's huber: 3.03887
[I 2021-07-30 09:47:05,156] Finished trial#18 with value: 3.7926711523555237 with parameters: {'objective': 'huber', 'learning_rate': 0.022658710643765925, 'n_estimators': 2873, 'max_depth': 10, 'num_leaves': 83872, 'max_bin': 59, 'feature_fraction': 0.7105246361635494, 'bagging_fraction': 0.7628505123292743, 'bagging_freq': 38, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0005641935282046279, 'reg_lambda': 0.0002841056831932838}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.7542936936366365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7542936936366365
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.6833068854528686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6833068854528686
[LightGBM] [Warning] bagging_freq is set=38, subsample_freq=0 will be ignored. Current value: bagging_freq=38
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[647]	valid_0's huber: 3.04572
[I 2021-07-30 09:47:20,815] Finished trial#19 with value: 3.8004699725736812 with parameters: {'objective': 'huber', 'learning_rate': 0.03664486119257212, 'n_estimators': 2818, 'max_depth': 7, 'num_leaves': 84009, 'max_bin': 59, 'feature_fraction': 0.6833068854528686, 'bagging_fraction': 0.7542936936366365, 'bagging_freq': 38, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0005103552772714389, 'reg_lambda': 0.00043591919273451416}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.7173182209522846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7173182209522846
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.1015105877315211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1015105877315211
[LightGBM] [Warning] bagging_freq is set=36, subsample_freq=0 will be ignored. Current value: bagging_freq=36
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1622]	valid_0's huber: 3.16404
[I 2021-07-30 09:47:52,409] Finished trial#20 with value: 3.9343974027730053 with parameters: {'objective': 'huber', 'learning_rate': 0.042746448396174044, 'n_estimators': 3484, 'max_depth': 7, 'num_leaves': 80347, 'max_bin': 64, 'feature_fraction': 0.1015105877315211, 'bagging_fraction': 0.7173182209522846, 'bagging_freq': 36, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 5.307707038364019e-05, 'reg_lambda': 0.0004307620878595993}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.7638240527925797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7638240527925797
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.6999655391979354, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6999655391979354
[LightGBM] [Warning] bagging_freq is set=39, subsample_freq=0 will be ignored. Current value: bagging_freq=39
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[904]	valid_0's huber: 3.06277
[I 2021-07-30 09:49:12,071] Finished trial#21 with value: 3.8201274166705286 with parameters: {'objective': 'huber', 'learning_rate': 0.023678223530251768, 'n_estimators': 2875, 'max_depth': 11, 'num_leaves': 85492, 'max_bin': 42, 'feature_fraction': 0.6999655391979354, 'bagging_fraction': 0.7638240527925797, 'bagging_freq': 39, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0005268561949562713, 'reg_lambda': 0.00029961373717614663}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.4921964630371289, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4921964630371289
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.6536952918443675, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6536952918443675
[LightGBM] [Warning] bagging_freq is set=32, subsample_freq=0 will be ignored. Current value: bagging_freq=32
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[543]	valid_0's huber: 3.12804
[I 2021-07-30 09:49:15,877] Finished trial#22 with value: 3.892287833312041 with parameters: {'objective': 'huber', 'learning_rate': 0.04971372898309289, 'n_estimators': 3103, 'max_depth': 3, 'num_leaves': 54787, 'max_bin': 69, 'feature_fraction': 0.6536952918443675, 'bagging_fraction': 0.4921964630371289, 'bagging_freq': 32, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0004999758207552841, 'reg_lambda': 4.4983775072797236e-05}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.7746053198719767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7746053198719767
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.5981088145905835, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5981088145905835
[LightGBM] [Warning] bagging_freq is set=55, subsample_freq=0 will be ignored. Current value: bagging_freq=55
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1961]	valid_0's huber: 3.0488
[I 2021-07-30 09:49:55,081] Finished trial#23 with value: 3.8043432638504955 with parameters: {'objective': 'huber', 'learning_rate': 0.01226301031139035, 'n_estimators': 4054, 'max_depth': 7, 'num_leaves': 86960, 'max_bin': 32, 'feature_fraction': 0.5981088145905835, 'bagging_fraction': 0.7746053198719767, 'bagging_freq': 55, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 7.919833314939191e-05, 'reg_lambda': 0.00011576474177159826}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.9917539412970778, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9917539412970778
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.4093091664475429, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4093091664475429
[LightGBM] [Warning] bagging_freq is set=64, subsample_freq=0 will be ignored. Current value: bagging_freq=64
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[2141]	valid_0's huber: 3.06159
[I 2021-07-30 09:50:45,121] Finished trial#24 with value: 3.818323784467301 with parameters: {'objective': 'huber', 'learning_rate': 0.012149186637273109, 'n_estimators': 4168, 'max_depth': 7, 'num_leaves': 115829, 'max_bin': 54, 'feature_fraction': 0.4093091664475429, 'bagging_fraction': 0.9917539412970778, 'bagging_freq': 64, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 8.966445832887308e-05, 'reg_lambda': 0.0017863332266221466}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.6823613076689165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6823613076689165
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3
[LightGBM] [Warning] feature_fraction is set=0.6059145252339869, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059145252339869
[LightGBM] [Warning] bagging_freq is set=50, subsample_freq=0 will be ignored. Current value: bagging_freq=50
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[4067]	valid_0's huber: 3.47393
[I 2021-07-30 09:51:26,708] Finished trial#25 with value: 4.289802886028182 with parameters: {'objective': 'huber', 'learning_rate': 0.0027348219317622964, 'n_estimators': 4067, 'max_depth': 5, 'num_leaves': 83120, 'max_bin': 30, 'feature_fraction': 0.6059145252339869, 'bagging_fraction': 0.6823613076689165, 'bagging_freq': 50, 'min_sum_hessian_in_leaf': 3, 'reg_alpha': 1.4618927444557164e-05, 'reg_lambda': 8.225625680858582e-05}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.9026317087445579, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9026317087445579
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.7527436704556205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7527436704556205
[LightGBM] [Warning] bagging_freq is set=71, subsample_freq=0 will be ignored. Current value: bagging_freq=71
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1870]	valid_0's huber: 3.04498
[I 2021-07-30 09:54:52,246] Finished trial#26 with value: 3.799879482631495 with parameters: {'objective': 'huber', 'learning_rate': 0.011749374903025805, 'n_estimators': 3366, 'max_depth': 11, 'num_leaves': 58544, 'max_bin': 83, 'feature_fraction': 0.7527436704556205, 'bagging_fraction': 0.9026317087445579, 'bagging_freq': 71, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.00030184677701610015, 'reg_lambda': 3.402423084379285e-05}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.9228521717754079, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9228521717754079
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3
[LightGBM] [Warning] feature_fraction is set=0.7527762470501895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7527762470501895
[LightGBM] [Warning] bagging_freq is set=77, subsample_freq=0 will be ignored. Current value: bagging_freq=77
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[517]	valid_0's huber: 3.04864
[I 2021-07-30 09:56:06,332] Finished trial#27 with value: 3.8034851613780685 with parameters: {'objective': 'huber', 'learning_rate': 0.04414821708329902, 'n_estimators': 2431, 'max_depth': 11, 'num_leaves': 56642, 'max_bin': 83, 'feature_fraction': 0.7527762470501895, 'bagging_fraction': 0.9228521717754079, 'bagging_freq': 77, 'min_sum_hessian_in_leaf': 3, 'reg_alpha': 0.000702419883229247, 'reg_lambda': 3.1762209051481426e-05}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.8758478312991407, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8758478312991407
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.8899246126097313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8899246126097313
[LightGBM] [Warning] bagging_freq is set=92, subsample_freq=0 will be ignored. Current value: bagging_freq=92
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[292]	valid_0's huber: 3.05455
[I 2021-07-30 09:57:14,289] Finished trial#28 with value: 3.810029144904165 with parameters: {'objective': 'huber', 'learning_rate': 0.07204807080042609, 'n_estimators': 3397, 'max_depth': 12, 'num_leaves': 76264, 'max_bin': 124, 'feature_fraction': 0.8899246126097313, 'bagging_fraction': 0.8758478312991407, 'bagging_freq': 92, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0003030793748444906, 'reg_lambda': 0.010256821647353488}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.6412851430448473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6412851430448473
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.7522450254060485, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7522450254060485
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[742]	valid_0's huber: 3.0483
[I 2021-07-30 09:58:21,536] Finished trial#29 with value: 3.8030473446645936 with parameters: {'objective': 'huber', 'learning_rate': 0.028929974714417418, 'n_estimators': 2514, 'max_depth': 10, 'num_leaves': 36940, 'max_bin': 78, 'feature_fraction': 0.7522450254060485, 'bagging_fraction': 0.6412851430448473, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.0009176071390351593, 'reg_lambda': 0.0017618250489822155}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.9704001426765779, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9704001426765779
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3
[LightGBM] [Warning] feature_fraction is set=0.6710325552029465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6710325552029465
[LightGBM] [Warning] bagging_freq is set=70, subsample_freq=0 will be ignored. Current value: bagging_freq=70
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[2520]	valid_0's huber: 3.06604
[I 2021-07-30 09:58:56,658] Finished trial#30 with value: 3.823254851751235 with parameters: {'objective': 'huber', 'learning_rate': 0.00984335915803808, 'n_estimators': 3196, 'max_depth': 5, 'num_leaves': 27431, 'max_bin': 57, 'feature_fraction': 0.6710325552029465, 'bagging_fraction': 0.9704001426765779, 'bagging_freq': 70, 'min_sum_hessian_in_leaf': 3, 'reg_alpha': 0.00011681461786268766, 'reg_lambda': 0.0005115049144598653}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.6396853233058931, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6396853233058931
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.7524023291257742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7524023291257742
[LightGBM] [Warning] bagging_freq is set=99, subsample_freq=0 will be ignored. Current value: bagging_freq=99
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[616]	valid_0's huber: 3.05358
[I 2021-07-30 09:59:51,638] Finished trial#31 with value: 3.8094901790794977 with parameters: {'objective': 'huber', 'learning_rate': 0.03616091690115381, 'n_estimators': 2620, 'max_depth': 10, 'num_leaves': 32095, 'max_bin': 80, 'feature_fraction': 0.7524023291257742, 'bagging_fraction': 0.6396853233058931, 'bagging_freq': 99, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.0011022371675389773, 'reg_lambda': 0.0017993464338108467}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.5943488274646955, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5943488274646955
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.7595868045958434, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7595868045958434
[LightGBM] [Warning] bagging_freq is set=92, subsample_freq=0 will be ignored. Current value: bagging_freq=92
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1128]	valid_0's huber: 3.03943
[I 2021-07-30 10:01:38,789] Finished trial#32 with value: 3.7930777392503137 with parameters: {'objective': 'huber', 'learning_rate': 0.019152284872192307, 'n_estimators': 2424, 'max_depth': 10, 'num_leaves': 54842, 'max_bin': 48, 'feature_fraction': 0.7595868045958434, 'bagging_fraction': 0.5943488274646955, 'bagging_freq': 92, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0008870510765252565, 'reg_lambda': 0.0016712067837681723}. Best is trial#18 with value: 3.7926711523555237.
[LightGBM] [Warning] bagging_fraction is set=0.5327204984599822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5327204984599822
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.598154202679297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.598154202679297
[LightGBM] [Warning] bagging_freq is set=90, subsample_freq=0 will be ignored. Current value: bagging_freq=90
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1109]	valid_0's huber: 3.03815
[I 2021-07-30 10:02:31,312] Finished trial#33 with value: 3.7919369621688612 with parameters: {'objective': 'huber', 'learning_rate': 0.019350430068684022, 'n_estimators': 3233, 'max_depth': 8, 'num_leaves': 59529, 'max_bin': 49, 'feature_fraction': 0.598154202679297, 'bagging_fraction': 0.5327204984599822, 'bagging_freq': 90, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0002952726784851808, 'reg_lambda': 0.0005873987884004217}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.508003714589096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.508003714589096
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.5699826985135437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5699826985135437
[LightGBM] [Warning] bagging_freq is set=91, subsample_freq=0 will be ignored. Current value: bagging_freq=91
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1233]	valid_0's huber: 3.07328
[I 2021-07-30 10:06:19,664] Finished trial#34 with value: 3.8310560827828137 with parameters: {'objective': 'huber', 'learning_rate': 0.018346630421293062, 'n_estimators': 3172, 'max_depth': 13, 'num_leaves': 56711, 'max_bin': 43, 'feature_fraction': 0.5699826985135437, 'bagging_fraction': 0.508003714589096, 'bagging_freq': 91, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.00316599727349008, 'reg_lambda': 0.0006959190156294999}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.5516644808826615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5516644808826615
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.42683272336067446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42683272336067446
[LightGBM] [Warning] bagging_freq is set=86, subsample_freq=0 will be ignored. Current value: bagging_freq=86
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[3909]	valid_0's huber: 6.43036
[I 2021-07-30 10:09:06,713] Finished trial#35 with value: 7.589489492973248 with parameters: {'objective': 'huber', 'learning_rate': 0.00012678322600779288, 'n_estimators': 3909, 'max_depth': 8, 'num_leaves': 49815, 'max_bin': 27, 'feature_fraction': 0.42683272336067446, 'bagging_fraction': 0.5516644808826615, 'bagging_freq': 86, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.0002062526904900007, 'reg_lambda': 0.0013207160286668837}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.43841617314837067, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43841617314837067
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.9242050558488892, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9242050558488892
[LightGBM] [Warning] bagging_freq is set=75, subsample_freq=0 will be ignored. Current value: bagging_freq=75
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[2344]	valid_0's huber: 3.68175
[I 2021-07-30 10:15:29,704] Finished trial#36 with value: 4.524714355522566 with parameters: {'objective': 'huber', 'learning_rate': 0.0034815911167676203, 'n_estimators': 2344, 'max_depth': 12, 'num_leaves': 44199, 'max_bin': 198, 'feature_fraction': 0.9242050558488892, 'bagging_fraction': 0.43841617314837067, 'bagging_freq': 75, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.00035054526982291093, 'reg_lambda': 0.022665133001085486}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.5516403430261535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5516403430261535
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3
[LightGBM] [Warning] feature_fraction is set=0.4424401195062898, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4424401195062898
[LightGBM] [Warning] bagging_freq is set=85, subsample_freq=0 will be ignored. Current value: bagging_freq=85
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[3051]	valid_0's huber: 3.05622
[I 2021-07-30 10:17:41,960] Finished trial#37 with value: 3.8120590146765205 with parameters: {'objective': 'huber', 'learning_rate': 0.008084579767888518, 'n_estimators': 4434, 'max_depth': 8, 'num_leaves': 61821, 'max_bin': 54, 'feature_fraction': 0.4424401195062898, 'bagging_fraction': 0.5516403430261535, 'bagging_freq': 85, 'min_sum_hessian_in_leaf': 3, 'reg_alpha': 3.563977451181323e-05, 'reg_lambda': 0.009296494877935277}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.6034812898497237, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6034812898497237
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.6010202140772755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6010202140772755
[LightGBM] [Warning] bagging_freq is set=92, subsample_freq=0 will be ignored. Current value: bagging_freq=92
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[99]	valid_0's l2: 65.2361
[I 2021-07-30 10:18:04,698] Finished trial#38 with value: 5.056897151658068 with parameters: {'objective': 'mse', 'learning_rate': 0.01623655167096476, 'n_estimators': 3619, 'max_depth': 11, 'num_leaves': 74064, 'max_bin': 47, 'feature_fraction': 0.6010202140772755, 'bagging_fraction': 0.6034812898497237, 'bagging_freq': 92, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.00025666479324748753, 'reg_lambda': 2.07583209762892e-05}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.4762262426458336, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4762262426458336
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.7992923022125988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7992923022125988
[LightGBM] [Warning] bagging_freq is set=71, subsample_freq=0 will be ignored. Current value: bagging_freq=71
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[316]	valid_0's huber: 3.05832
[I 2021-07-30 10:19:18,403] Finished trial#39 with value: 3.8140512030144893 with parameters: {'objective': 'huber', 'learning_rate': 0.06690538996977416, 'n_estimators': 1753, 'max_depth': 13, 'num_leaves': 16482, 'max_bin': 115, 'feature_fraction': 0.7992923022125988, 'bagging_fraction': 0.4762262426458336, 'bagging_freq': 71, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.000173631020148919, 'reg_lambda': 0.0029120755879224556}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.2973697282147637, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2973697282147637
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10
[LightGBM] [Warning] feature_fraction is set=0.5332210737212704, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5332210737212704
[LightGBM] [Warning] bagging_freq is set=65, subsample_freq=0 will be ignored. Current value: bagging_freq=65
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[3754]	valid_0's huber: 3.77916
[I 2021-07-30 10:24:13,161] Finished trial#40 with value: 4.63382498881412 with parameters: {'objective': 'huber', 'learning_rate': 0.0022022494897348736, 'n_estimators': 3754, 'max_depth': 10, 'num_leaves': 63696, 'max_bin': 139, 'feature_fraction': 0.5332210737212704, 'bagging_fraction': 0.2973697282147637, 'bagging_freq': 65, 'min_sum_hessian_in_leaf': 10, 'reg_alpha': 0.0008702464637721438, 'reg_lambda': 0.0006947639357812006}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.7499830708089195, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7499830708089195
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.706818119425737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.706818119425737
[LightGBM] [Warning] bagging_freq is set=44, subsample_freq=0 will be ignored. Current value: bagging_freq=44
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[723]	valid_0's huber: 3.05661
[I 2021-07-30 10:24:30,707] Finished trial#41 with value: 3.8125813631956187 with parameters: {'objective': 'huber', 'learning_rate': 0.03409484596625683, 'n_estimators': 2724, 'max_depth': 6, 'num_leaves': 47578, 'max_bin': 69, 'feature_fraction': 0.706818119425737, 'bagging_fraction': 0.7499830708089195, 'bagging_freq': 44, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.0004592466058360645, 'reg_lambda': 0.00037131859221971065}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.7152825823461539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7152825823461539
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.6439792191776892, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6439792191776892
[LightGBM] [Warning] bagging_freq is set=43, subsample_freq=0 will be ignored. Current value: bagging_freq=43
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1260]	valid_0's huber: 3.04818
[I 2021-07-30 10:25:36,867] Finished trial#42 with value: 3.8038165109855617 with parameters: {'objective': 'huber', 'learning_rate': 0.017226824688489684, 'n_estimators': 3104, 'max_depth': 8, 'num_leaves': 92667, 'max_bin': 22, 'feature_fraction': 0.6439792191776892, 'bagging_fraction': 0.7152825823461539, 'bagging_freq': 43, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.0007710614883731447, 'reg_lambda': 0.0011025574781199827}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.5938935046361394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5938935046361394
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.6727850877020755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6727850877020755
[LightGBM] [Warning] bagging_freq is set=83, subsample_freq=0 will be ignored. Current value: bagging_freq=83
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1017]	valid_0's huber: 3.05352
[I 2021-07-30 10:25:50,159] Finished trial#43 with value: 3.8091076390401777 with parameters: {'objective': 'huber', 'learning_rate': 0.022798348739256694, 'n_estimators': 3352, 'max_depth': 6, 'num_leaves': 68895, 'max_bin': 62, 'feature_fraction': 0.6727850877020755, 'bagging_fraction': 0.5938935046361394, 'bagging_freq': 83, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.00039329474032702465, 'reg_lambda': 0.0029881777373788145}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.677823395527003, subsample=1.0 will be ignored. Current value: bagging_fraction=0.677823395527003
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.7508872358096881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7508872358096881
[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1433]	valid_0's l2: 65.3455
[I 2021-07-30 10:26:45,379] Finished trial#44 with value: 5.000360969217518 with parameters: {'objective': 'mse', 'learning_rate': 0.0012138278249222726, 'n_estimators': 2993, 'max_depth': 9, 'num_leaves': 78120, 'max_bin': 88, 'feature_fraction': 0.7508872358096881, 'bagging_fraction': 0.677823395527003, 'bagging_freq': 26, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.0030165977760884728, 'reg_lambda': 0.0002563665393892975}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.893290216296366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.893290216296366
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.8592518790349761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8592518790349761
[LightGBM] [Warning] bagging_freq is set=56, subsample_freq=0 will be ignored. Current value: bagging_freq=56
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[2194]	valid_0's huber: 3.08178
[I 2021-07-30 10:33:22,979] Finished trial#45 with value: 3.8395343992102386 with parameters: {'objective': 'huber', 'learning_rate': 0.009065371762313122, 'n_estimators': 2194, 'max_depth': 14, 'num_leaves': 61718, 'max_bin': 45, 'feature_fraction': 0.8592518790349761, 'bagging_fraction': 0.893290216296366, 'bagging_freq': 56, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.00013634163521306685, 'reg_lambda': 0.0005579794178470223}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.8376041972461529, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8376041972461529
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3
[LightGBM] [Warning] feature_fraction is set=0.4802548040698412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4802548040698412
[LightGBM] [Warning] bagging_freq is set=95, subsample_freq=0 will be ignored. Current value: bagging_freq=95
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[2650]	valid_0's huber: 3.41738
[I 2021-07-30 10:33:45,248] Finished trial#46 with value: 4.225301608051564 with parameters: {'objective': 'huber', 'learning_rate': 0.0047513652314394575, 'n_estimators': 2650, 'max_depth': 4, 'num_leaves': 51927, 'max_bin': 73, 'feature_fraction': 0.4802548040698412, 'bagging_fraction': 0.8376041972461529, 'bagging_freq': 95, 'min_sum_hessian_in_leaf': 3, 'reg_alpha': 0.0006227752612544977, 'reg_lambda': 0.0001301770654344308}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.5786853409347364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5786853409347364
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=5, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=5
[LightGBM] [Warning] feature_fraction is set=0.6230938268092834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6230938268092834
[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[357]	valid_0's huber: 3.04633
[I 2021-07-30 10:33:54,041] Finished trial#47 with value: 3.8009670050720246 with parameters: {'objective': 'huber', 'learning_rate': 0.0670708789809563, 'n_estimators': 1872, 'max_depth': 7, 'num_leaves': 40195, 'max_bin': 97, 'feature_fraction': 0.6230938268092834, 'bagging_fraction': 0.5786853409347364, 'bagging_freq': 21, 'min_sum_hessian_in_leaf': 5, 'reg_alpha': 0.0002423083453741275, 'reg_lambda': 7.102715208652104e-05}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.6373755362637794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6373755362637794
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2
[LightGBM] [Warning] feature_fraction is set=0.5559628660327547, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5559628660327547
[LightGBM] [Warning] bagging_freq is set=61, subsample_freq=0 will be ignored. Current value: bagging_freq=61
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[107]	valid_0's l2: 67.3135
[I 2021-07-30 10:33:59,325] Finished trial#48 with value: 5.161671808036274 with parameters: {'objective': 'mse', 'learning_rate': 0.014347940749593762, 'n_estimators': 1479, 'max_depth': 8, 'num_leaves': 71400, 'max_bin': 37, 'feature_fraction': 0.5559628660327547, 'bagging_fraction': 0.6373755362637794, 'bagging_freq': 61, 'min_sum_hessian_in_leaf': 2, 'reg_alpha': 0.0012110377448255425, 'reg_lambda': 0.005142568292106602}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.7217436193996434, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7217436193996434
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1
[LightGBM] [Warning] feature_fraction is set=0.7178834367251673, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7178834367251673
[LightGBM] [Warning] bagging_freq is set=31, subsample_freq=0 will be ignored. Current value: bagging_freq=31
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[672]	valid_0's huber: 3.05652
[I 2021-07-30 10:35:05,030] Finished trial#49 with value: 3.8123362057519694 with parameters: {'objective': 'huber', 'learning_rate': 0.031565593722402675, 'n_estimators': 3338, 'max_depth': 12, 'num_leaves': 95684, 'max_bin': 54, 'feature_fraction': 0.7178834367251673, 'bagging_fraction': 0.7217436193996434, 'bagging_freq': 31, 'min_sum_hessian_in_leaf': 1, 'reg_alpha': 0.00033458643494776227, 'reg_lambda': 0.000825549439400938}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.9531598952918143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9531598952918143
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=5, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=5
[LightGBM] [Warning] feature_fraction is set=0.9406058650880524, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9406058650880524
[LightGBM] [Warning] bagging_freq is set=79, subsample_freq=0 will be ignored. Current value: bagging_freq=79
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[933]	valid_0's huber: 3.04219
[I 2021-07-30 10:36:08,007] Finished trial#50 with value: 3.7965626718866865 with parameters: {'objective': 'huber', 'learning_rate': 0.021132167073851432, 'n_estimators': 4997, 'max_depth': 10, 'num_leaves': 66514, 'max_bin': 91, 'feature_fraction': 0.9406058650880524, 'bagging_fraction': 0.9531598952918143, 'bagging_freq': 79, 'min_sum_hessian_in_leaf': 5, 'reg_alpha': 0.002763840800214353, 'reg_lambda': 0.0003558481360109256}. Best is trial#33 with value: 3.7919369621688612.
[LightGBM] [Warning] bagging_fraction is set=0.9415473374248757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9415473374248757
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8305770029479225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8305770029479225
[LightGBM] [Warning] bagging_freq is set=88, subsample_freq=0 will be ignored. Current value: bagging_freq=88
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1056]	valid_0's huber: 3.03572
[I 2021-07-30 10:37:08,887] Finished trial#51 with value: 3.789263307745388 with parameters: {'objective': 'huber', 'learning_rate': 0.019992918244378835, 'n_estimators': 2337, 'max_depth': 10, 'num_leaves': 59158, 'max_bin': 92, 'feature_fraction': 0.8305770029479225, 'bagging_fraction': 0.9415473374248757, 'bagging_freq': 88, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.012284953850265389, 'reg_lambda': 0.0003108165898678094}. Best is trial#51 with value: 3.789263307745388.
[LightGBM] [Warning] bagging_fraction is set=0.9921595503128002, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9921595503128002
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.9584437167906372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9584437167906372
[LightGBM] [Warning] bagging_freq is set=88, subsample_freq=0 will be ignored. Current value: bagging_freq=88
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1048]	valid_0's huber: 3.03196
[I 2021-07-30 10:38:20,935] Finished trial#52 with value: 3.7846656477678904 with parameters: {'objective': 'huber', 'learning_rate': 0.020167215618355706, 'n_estimators': 2340, 'max_depth': 10, 'num_leaves': 65225, 'max_bin': 114, 'feature_fraction': 0.9584437167906372, 'bagging_fraction': 0.9921595503128002, 'bagging_freq': 88, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.022306274438153723, 'reg_lambda': 0.000140317046125693}. Best is trial#52 with value: 3.7846656477678904.
[LightGBM] [Warning] bagging_fraction is set=0.9719799904652136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9719799904652136
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.9563067578301593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9563067578301593
[LightGBM] [Warning] bagging_freq is set=89, subsample_freq=0 will be ignored. Current value: bagging_freq=89
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[1969]	valid_0's huber: 3.18572
[I 2021-07-30 10:39:53,753] Finished trial#53 with value: 3.961477382360067 with parameters: {'objective': 'huber', 'learning_rate': 0.00645446727357867, 'n_estimators': 1969, 'max_depth': 9, 'num_leaves': 66875, 'max_bin': 110, 'feature_fraction': 0.9563067578301593, 'bagging_fraction': 0.9719799904652136, 'bagging_freq': 89, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.024238710463655604, 'reg_lambda': 0.00015557148061940315}. Best is trial#52 with value: 3.7846656477678904.
[LightGBM] [Warning] bagging_fraction is set=0.940109008344763, subsample=1.0 will be ignored. Current value: bagging_fraction=0.940109008344763
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.950448449255167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.950448449255167
[LightGBM] [Warning] bagging_freq is set=80, subsample_freq=0 will be ignored. Current value: bagging_freq=80
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[872]	valid_0's huber: 3.0477
[I 2021-07-30 10:40:52,710] Finished trial#54 with value: 3.802714039279133 with parameters: {'objective': 'huber', 'learning_rate': 0.02362690345772771, 'n_estimators': 2311, 'max_depth': 10, 'num_leaves': 45286, 'max_bin': 133, 'feature_fraction': 0.950448449255167, 'bagging_fraction': 0.940109008344763, 'bagging_freq': 80, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.057654489853077785, 'reg_lambda': 0.00032715411042088117}. Best is trial#52 with value: 3.7846656477678904.
[LightGBM] [Warning] bagging_fraction is set=0.9523363366303327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9523363366303327
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8435459732326129, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8435459732326129
[LightGBM] [Warning] bagging_freq is set=96, subsample_freq=0 will be ignored. Current value: bagging_freq=96
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[1037]	valid_0's huber: 3.02624
[I 2021-07-30 10:41:35,753] Finished trial#55 with value: 3.778722885220352 with parameters: {'objective': 'huber', 'learning_rate': 0.021322644854364664, 'n_estimators': 4814, 'max_depth': 9, 'num_leaves': 53070, 'max_bin': 157, 'feature_fraction': 0.8435459732326129, 'bagging_fraction': 0.9523363366303327, 'bagging_freq': 96, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.014467721541940098, 'reg_lambda': 0.0002547720501729886}. Best is trial#55 with value: 3.778722885220352.
[LightGBM] [Warning] bagging_fraction is set=0.9999754966126708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9999754966126708
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8290547280458402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290547280458402
[LightGBM] [Warning] bagging_freq is set=95, subsample_freq=0 will be ignored. Current value: bagging_freq=95
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[445]	valid_0's huber: 3.02666
[I 2021-07-30 10:41:59,731] Finished trial#56 with value: 3.7794252572259546 with parameters: {'objective': 'huber', 'learning_rate': 0.04885882027522642, 'n_estimators': 2181, 'max_depth': 9, 'num_leaves': 51549, 'max_bin': 161, 'feature_fraction': 0.8290547280458402, 'bagging_fraction': 0.9999754966126708, 'bagging_freq': 95, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.014800466646053263, 'reg_lambda': 8.803274324191414e-05}. Best is trial#55 with value: 3.778722885220352.
[LightGBM] [Warning] bagging_fraction is set=0.9988852686684219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9988852686684219
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8407065351725485, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8407065351725485
[LightGBM] [Warning] bagging_freq is set=96, subsample_freq=0 will be ignored. Current value: bagging_freq=96
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[403]	valid_0's huber: 3.02785
[I 2021-07-30 10:42:21,087] Finished trial#57 with value: 3.7808629160028016 with parameters: {'objective': 'huber', 'learning_rate': 0.0547670568114682, 'n_estimators': 1206, 'max_depth': 9, 'num_leaves': 38384, 'max_bin': 170, 'feature_fraction': 0.8407065351725485, 'bagging_fraction': 0.9988852686684219, 'bagging_freq': 96, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.013477542337344288, 'reg_lambda': 9.143201844031857e-05}. Best is trial#55 with value: 3.778722885220352.
[LightGBM] [Warning] bagging_fraction is set=0.9906929910647415, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9906929910647415
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8434158792825723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8434158792825723
[LightGBM] [Warning] bagging_freq is set=96, subsample_freq=0 will be ignored. Current value: bagging_freq=96
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[220]	valid_0's huber: 3.0303
[I 2021-07-30 10:42:30,941] Finished trial#58 with value: 3.783252511418436 with parameters: {'objective': 'huber', 'learning_rate': 0.09973134070444686, 'n_estimators': 1024, 'max_depth': 8, 'num_leaves': 25309, 'max_bin': 159, 'feature_fraction': 0.8434158792825723, 'bagging_fraction': 0.9906929910647415, 'bagging_freq': 96, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.013098410617803442, 'reg_lambda': 8.455490821530563e-05}. Best is trial#55 with value: 3.778722885220352.
[LightGBM] [Warning] bagging_fraction is set=0.9859606099059971, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9859606099059971
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8427298537588153, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8427298537588153
[LightGBM] [Warning] bagging_freq is set=95, subsample_freq=0 will be ignored. Current value: bagging_freq=95
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[411]	valid_0's huber: 3.02924
[I 2021-07-30 10:42:53,001] Finished trial#59 with value: 3.782054037905948 with parameters: {'objective': 'huber', 'learning_rate': 0.0523917487198133, 'n_estimators': 888, 'max_depth': 9, 'num_leaves': 22318, 'max_bin': 169, 'feature_fraction': 0.8427298537588153, 'bagging_fraction': 0.9859606099059971, 'bagging_freq': 95, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.014503125685205768, 'reg_lambda': 8.388261777206486e-05}. Best is trial#55 with value: 3.778722885220352.
[LightGBM] [Warning] bagging_fraction is set=0.995537721685593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.995537721685593
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8877554721848084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8877554721848084
[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[255]	valid_0's huber: 3.02863
[I 2021-07-30 10:43:08,589] Finished trial#60 with value: 3.781579974879018 with parameters: {'objective': 'huber', 'learning_rate': 0.0823974853790776, 'n_estimators': 1078, 'max_depth': 9, 'num_leaves': 11896, 'max_bin': 159, 'feature_fraction': 0.8877554721848084, 'bagging_fraction': 0.995537721685593, 'bagging_freq': 97, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.034803761318182636, 'reg_lambda': 8.139715949780097e-05}. Best is trial#55 with value: 3.778722885220352.
[LightGBM] [Warning] bagging_fraction is set=0.9998386963896833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9998386963896833
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8856476112904522, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8856476112904522
[LightGBM] [Warning] bagging_freq is set=95, subsample_freq=0 will be ignored. Current value: bagging_freq=95
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[237]	valid_0's huber: 3.02282
[I 2021-07-30 10:43:23,262] Finished trial#61 with value: 3.774418940623943 with parameters: {'objective': 'huber', 'learning_rate': 0.0903658307224738, 'n_estimators': 982, 'max_depth': 9, 'num_leaves': 11145, 'max_bin': 163, 'feature_fraction': 0.8856476112904522, 'bagging_fraction': 0.9998386963896833, 'bagging_freq': 95, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.03590079914389519, 'reg_lambda': 5.858677893287671e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9996326856625259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9996326856625259
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8566000132899807, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8566000132899807
[LightGBM] [Warning] bagging_freq is set=96, subsample_freq=0 will be ignored. Current value: bagging_freq=96
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[222]	valid_0's huber: 3.02677
[I 2021-07-30 10:43:37,012] Finished trial#62 with value: 3.7796627578562987 with parameters: {'objective': 'huber', 'learning_rate': 0.09943683335877965, 'n_estimators': 979, 'max_depth': 9, 'num_leaves': 7142, 'max_bin': 161, 'feature_fraction': 0.8566000132899807, 'bagging_fraction': 0.9996326856625259, 'bagging_freq': 96, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.09366948059775637, 'reg_lambda': 5.740554717395055e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9925916725009053, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9925916725009053
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.9017351548512986, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9017351548512986
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[250]	valid_0's huber: 3.02446
[I 2021-07-30 10:43:51,839] Finished trial#63 with value: 3.7770290814777088 with parameters: {'objective': 'huber', 'learning_rate': 0.08438639845342384, 'n_estimators': 605, 'max_depth': 9, 'num_leaves': 7543, 'max_bin': 174, 'feature_fraction': 0.9017351548512986, 'bagging_fraction': 0.9925916725009053, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.09702553807434962, 'reg_lambda': 4.9732266421279234e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9201732053030912, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9201732053030912
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8930097457624218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8930097457624218
[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[227]	valid_0's huber: 3.02331
[I 2021-07-30 10:44:05,445] Finished trial#64 with value: 3.7755519093120755 with parameters: {'objective': 'huber', 'learning_rate': 0.0922710657904953, 'n_estimators': 589, 'max_depth': 9, 'num_leaves': 8424, 'max_bin': 185, 'feature_fraction': 0.8930097457624218, 'bagging_fraction': 0.9201732053030912, 'bagging_freq': 98, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.09438368567619639, 'reg_lambda': 4.4777998908968164e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.8755135289451459, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8755135289451459
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.8996420512752439, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8996420512752439
[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[250]	valid_0's huber: 3.04462
[I 2021-07-30 10:44:12,907] Finished trial#65 with value: 3.798606400869784 with parameters: {'objective': 'huber', 'learning_rate': 0.08866095428784404, 'n_estimators': 588, 'max_depth': 7, 'num_leaves': 3571, 'max_bin': 185, 'feature_fraction': 0.8996420512752439, 'bagging_fraction': 0.8755135289451459, 'bagging_freq': 98, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 0.09003892140127616, 'reg_lambda': 5.277319080415267e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9076177000611081, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9076177000611081
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.9965893050381972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9965893050381972
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[25]	valid_0's l1: 3.95522
[I 2021-07-30 10:44:15,438] Finished trial#66 with value: 3.9552185441119176 with parameters: {'objective': 'mae', 'learning_rate': 0.060572742234414265, 'n_estimators': 618, 'max_depth': 6, 'num_leaves': 7844, 'max_bin': 213, 'feature_fraction': 0.9965893050381972, 'bagging_fraction': 0.9076177000611081, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 0.09080543531347768, 'reg_lambda': 2.154485428737076e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9603846440413004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9603846440413004
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8831364797710883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8831364797710883
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[131]	valid_0's huber: 3.38814
[I 2021-07-30 10:44:22,111] Finished trial#67 with value: 4.192839389270926 with parameters: {'objective': 'huber', 'learning_rate': 0.07859624824374968, 'n_estimators': 131, 'max_depth': 9, 'num_leaves': 12744, 'max_bin': 178, 'feature_fraction': 0.8831364797710883, 'bagging_fraction': 0.9603846440413004, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.051979990741979336, 'reg_lambda': 4.943291554115176e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.8392162141503281, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8392162141503281
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.8163632909488184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8163632909488184
[LightGBM] [Warning] bagging_freq is set=94, subsample_freq=0 will be ignored. Current value: bagging_freq=94
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[233]	valid_0's huber: 3.03843
[I 2021-07-30 10:44:45,086] Finished trial#68 with value: 3.7924836918329374 with parameters: {'objective': 'huber', 'learning_rate': 0.09953946145560374, 'n_estimators': 1389, 'max_depth': 11, 'num_leaves': 782, 'max_bin': 148, 'feature_fraction': 0.8163632909488184, 'bagging_fraction': 0.8392162141503281, 'bagging_freq': 94, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 0.040179561835373585, 'reg_lambda': 2.5380856364744143e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9272205497136079, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9272205497136079
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.9147513259175715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9147513259175715
[LightGBM] [Warning] bagging_freq is set=83, subsample_freq=0 will be ignored. Current value: bagging_freq=83
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[34]	valid_0's l2: 65.1077
[I 2021-07-30 10:44:50,280] Finished trial#69 with value: 5.0119294372187015 with parameters: {'objective': 'mse', 'learning_rate': 0.045249162149055173, 'n_estimators': 767, 'max_depth': 9, 'num_leaves': 31941, 'max_bin': 198, 'feature_fraction': 0.9147513259175715, 'bagging_fraction': 0.9272205497136079, 'bagging_freq': 83, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.008882048543972964, 'reg_lambda': 6.43639106919548e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.8093467575766463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8093467575766463
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.7825737397420197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7825737397420197
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[396]	valid_0's huber: 3.03106
[I 2021-07-30 10:45:01,938] Finished trial#70 with value: 3.784300526099308 with parameters: {'objective': 'huber', 'learning_rate': 0.055638721553133506, 'n_estimators': 396, 'max_depth': 8, 'num_leaves': 6449, 'max_bin': 169, 'feature_fraction': 0.7825737397420197, 'bagging_fraction': 0.8093467575766463, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.0700423787410578, 'reg_lambda': 1.0080330472039543e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9976750552743423, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9976750552743423
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.874748218406182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.874748218406182
[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[264]	valid_0's huber: 3.02645
[I 2021-07-30 10:45:17,255] Finished trial#71 with value: 3.778714321818473 with parameters: {'objective': 'huber', 'learning_rate': 0.08479364121827268, 'n_estimators': 1129, 'max_depth': 9, 'num_leaves': 11637, 'max_bin': 156, 'feature_fraction': 0.874748218406182, 'bagging_fraction': 0.9976750552743423, 'bagging_freq': 97, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.03502079091998712, 'reg_lambda': 3.839809732032995e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.9661379549606549, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9661379549606549
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8692618634957123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8692618634957123
[LightGBM] [Warning] bagging_freq is set=95, subsample_freq=0 will be ignored. Current value: bagging_freq=95
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[223]	valid_0's huber: 3.04424
[I 2021-07-30 10:45:41,995] Finished trial#72 with value: 3.798733965784288 with parameters: {'objective': 'huber', 'learning_rate': 0.09948108643568933, 'n_estimators': 1233, 'max_depth': 11, 'num_leaves': 17891, 'max_bin': 151, 'feature_fraction': 0.8692618634957123, 'bagging_fraction': 0.9661379549606549, 'bagging_freq': 95, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.018561001977999002, 'reg_lambda': 4.34324739783368e-05}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.996506261862958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.996506261862958
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.9257480790367394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9257480790367394
[LightGBM] [Warning] bagging_freq is set=86, subsample_freq=0 will be ignored. Current value: bagging_freq=86
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[299]	valid_0's huber: 3.0427
[I 2021-07-30 10:45:50,702] Finished trial#73 with value: 3.7962196865661166 with parameters: {'objective': 'huber', 'learning_rate': 0.07613616446665468, 'n_estimators': 791, 'max_depth': 7, 'num_leaves': 10185, 'max_bin': 178, 'feature_fraction': 0.9257480790367394, 'bagging_fraction': 0.996506261862958, 'bagging_freq': 86, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.03393619655273259, 'reg_lambda': 0.00010220723112449818}. Best is trial#61 with value: 3.774418940623943.
[LightGBM] [Warning] bagging_fraction is set=0.8835990951694892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8835990951694892
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.7866249424381657, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7866249424381657
[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[533]	valid_0's huber: 3.02241
[I 2021-07-30 10:46:07,629] Finished trial#74 with value: 3.77433718350238 with parameters: {'objective': 'huber', 'learning_rate': 0.04153405228128592, 'n_estimators': 1074, 'max_depth': 8, 'num_leaves': 21473, 'max_bin': 187, 'feature_fraction': 0.7866249424381657, 'bagging_fraction': 0.8835990951694892, 'bagging_freq': 93, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.099327837369119, 'reg_lambda': 1.737834771403329e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.891787556301681, subsample=1.0 will be ignored. Current value: bagging_fraction=0.891787556301681
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.9734853496776519, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9734853496776519
[LightGBM] [Warning] bagging_freq is set=92, subsample_freq=0 will be ignored. Current value: bagging_freq=92
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[521]	valid_0's huber: 3.03778
[I 2021-07-30 10:46:23,388] Finished trial#75 with value: 3.7913203457147833 with parameters: {'objective': 'huber', 'learning_rate': 0.04307098306628307, 'n_estimators': 1540, 'max_depth': 8, 'num_leaves': 15056, 'max_bin': 187, 'feature_fraction': 0.9734853496776519, 'bagging_fraction': 0.891787556301681, 'bagging_freq': 92, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.07158006359028353, 'reg_lambda': 1.897863303975994e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.8613097696111306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8613097696111306
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10
[LightGBM] [Warning] feature_fraction is set=0.783854590979624, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.783854590979624
[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[405]	valid_0's huber: 3.08589
[I 2021-07-30 10:46:41,390] Finished trial#76 with value: 3.8469780326037064 with parameters: {'objective': 'huber', 'learning_rate': 0.03760799633434468, 'n_estimators': 405, 'max_depth': 9, 'num_leaves': 20131, 'max_bin': 197, 'feature_fraction': 0.783854590979624, 'bagging_fraction': 0.8613097696111306, 'bagging_freq': 98, 'min_sum_hessian_in_leaf': 10, 'reg_alpha': 0.09828588178450483, 'reg_lambda': 1.604734508090013e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9184358807865223, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9184358807865223
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.8644652584422764, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8644652584422764
[LightGBM] [Warning] bagging_freq is set=89, subsample_freq=0 will be ignored. Current value: bagging_freq=89
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[335]	valid_0's huber: 3.03146
[I 2021-07-30 10:46:54,493] Finished trial#77 with value: 3.7843888636068503 with parameters: {'objective': 'huber', 'learning_rate': 0.06440026198461213, 'n_estimators': 1043, 'max_depth': 8, 'num_leaves': 4725, 'max_bin': 250, 'feature_fraction': 0.8644652584422764, 'bagging_fraction': 0.9184358807865223, 'bagging_freq': 89, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 0.045533703004369215, 'reg_lambda': 2.9976799291725084e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9463106769542531, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9463106769542531
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8194989862894054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8194989862894054
[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[287]	valid_0's huber: 3.04197
[I 2021-07-30 10:47:02,766] Finished trial#78 with value: 3.795850085417687 with parameters: {'objective': 'huber', 'learning_rate': 0.08345699960218585, 'n_estimators': 655, 'max_depth': 7, 'num_leaves': 2040, 'max_bin': 207, 'feature_fraction': 0.8194989862894054, 'bagging_fraction': 0.9463106769542531, 'bagging_freq': 93, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.07293914748562891, 'reg_lambda': 4.074170682348857e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9707610533277153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9707610533277153
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.9064256461953142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064256461953142
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[499]	valid_0's l1: 4.79742
[I 2021-07-30 10:47:11,810] Finished trial#79 with value: 4.797422595896806 with parameters: {'objective': 'mae', 'learning_rate': 0.000455105273332168, 'n_estimators': 499, 'max_depth': 6, 'num_leaves': 22543, 'max_bin': 144, 'feature_fraction': 0.9064256461953142, 'bagging_fraction': 0.9707610533277153, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.029839479099076634, 'reg_lambda': 6.294044322911814e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9315534184544114, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9315534184544114
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.8793849319487981, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8793849319487981
[LightGBM] [Warning] bagging_freq is set=85, subsample_freq=0 will be ignored. Current value: bagging_freq=85
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[169]	valid_0's huber: 4.6494
[I 2021-07-30 10:47:26,705] Finished trial#80 with value: 5.605860819347567 with parameters: {'objective': 'huber', 'learning_rate': 0.02796403381276023, 'n_estimators': 169, 'max_depth': 11, 'num_leaves': 8412, 'max_bin': 161, 'feature_fraction': 0.8793849319487981, 'bagging_fraction': 0.9315534184544114, 'bagging_freq': 85, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 0.01977669696378729, 'reg_lambda': 1.1777144371408445e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9774170670528092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9774170670528092
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.84767192821467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84767192821467
[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[398]	valid_0's huber: 3.02762
[I 2021-07-30 10:47:47,931] Finished trial#81 with value: 3.7806827790767032 with parameters: {'objective': 'huber', 'learning_rate': 0.05421428262053416, 'n_estimators': 1196, 'max_depth': 9, 'num_leaves': 38776, 'max_bin': 171, 'feature_fraction': 0.84767192821467, 'bagging_fraction': 0.9774170670528092, 'bagging_freq': 97, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.05720066861004972, 'reg_lambda': 2.679376771807674e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9016168374238066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9016168374238066
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.8041466548483662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8041466548483662
[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[437]	valid_0's huber: 3.02628
[I 2021-07-30 10:48:19,266] Finished trial#82 with value: 3.779032183254407 with parameters: {'objective': 'huber', 'learning_rate': 0.049004923061152825, 'n_estimators': 925, 'max_depth': 10, 'num_leaves': 34002, 'max_bin': 188, 'feature_fraction': 0.8041466548483662, 'bagging_fraction': 0.9016168374238066, 'bagging_freq': 97, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.058921711711693414, 'reg_lambda': 2.7470238578683793e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9012133337641658, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9012133337641658
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.8011528404267675, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8011528404267675
[LightGBM] [Warning] bagging_freq is set=91, subsample_freq=0 will be ignored. Current value: bagging_freq=91
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[570]	valid_0's huber: 3.02768
[I 2021-07-30 10:48:58,771] Finished trial#83 with value: 3.7805673683973344 with parameters: {'objective': 'huber', 'learning_rate': 0.037976390292026964, 'n_estimators': 765, 'max_depth': 10, 'num_leaves': 29663, 'max_bin': 190, 'feature_fraction': 0.8011528404267675, 'bagging_fraction': 0.9012133337641658, 'bagging_freq': 91, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.042016356279663124, 'reg_lambda': 3.9138675359626794e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.872140656825216, subsample=1.0 will be ignored. Current value: bagging_fraction=0.872140656825216
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.9279354436995565, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9279354436995565
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[338]	valid_0's huber: 3.02699
[I 2021-07-30 10:49:23,688] Finished trial#84 with value: 3.7788856448890633 with parameters: {'objective': 'huber', 'learning_rate': 0.06440575636484956, 'n_estimators': 874, 'max_depth': 10, 'num_leaves': 14793, 'max_bin': 154, 'feature_fraction': 0.9279354436995565, 'bagging_fraction': 0.872140656825216, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.09831667866520992, 'reg_lambda': 1.4850583484184593e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.8748273895271745, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8748273895271745
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.7759334195654164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7759334195654164
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[476]	valid_0's huber: 3.0332
[I 2021-07-30 10:49:55,928] Finished trial#85 with value: 3.7864623690288606 with parameters: {'objective': 'huber', 'learning_rate': 0.04648146496585074, 'n_estimators': 884, 'max_depth': 10, 'num_leaves': 15371, 'max_bin': 125, 'feature_fraction': 0.7759334195654164, 'bagging_fraction': 0.8748273895271745, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.07151529065149591, 'reg_lambda': 1.5340953548033494e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.8492007330087873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8492007330087873
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.9173977273607086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9173977273607086
[LightGBM] [Warning] bagging_freq is set=94, subsample_freq=0 will be ignored. Current value: bagging_freq=94
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[338]	valid_0's huber: 3.04506
[I 2021-07-30 10:50:38,412] Finished trial#86 with value: 3.7997610167374374 with parameters: {'objective': 'huber', 'learning_rate': 0.07034772703140242, 'n_estimators': 1339, 'max_depth': 12, 'num_leaves': 34798, 'max_bin': 175, 'feature_fraction': 0.9173977273607086, 'bagging_fraction': 0.8492007330087873, 'bagging_freq': 94, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.026946564623408404, 'reg_lambda': 2.4201633112195893e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.8148692149680168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148692149680168
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.9847335687061659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9847335687061659
[LightGBM] [Warning] bagging_freq is set=87, subsample_freq=0 will be ignored. Current value: bagging_freq=87
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[264]	valid_0's huber: 3.77506
[I 2021-07-30 10:50:46,817] Finished trial#87 with value: 4.629100896713476 with parameters: {'objective': 'huber', 'learning_rate': 0.03050957950984774, 'n_estimators': 264, 'max_depth': 8, 'num_leaves': 26053, 'max_bin': 153, 'feature_fraction': 0.9847335687061659, 'bagging_fraction': 0.8148692149680168, 'bagging_freq': 87, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.005664297788640142, 'reg_lambda': 1.2689878886546814e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.7895161910690447, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7895161910690447
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.9334836197103685, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9334836197103685
[LightGBM] [Warning] bagging_freq is set=98, subsample_freq=0 will be ignored. Current value: bagging_freq=98
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[364]	valid_0's huber: 3.03779
[I 2021-07-30 10:51:21,452] Finished trial#88 with value: 3.7906848770701678 with parameters: {'objective': 'huber', 'learning_rate': 0.06117243890021935, 'n_estimators': 692, 'max_depth': 11, 'num_leaves': 20301, 'max_bin': 192, 'feature_fraction': 0.9334836197103685, 'bagging_fraction': 0.7895161910690447, 'bagging_freq': 98, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.047115247236105356, 'reg_lambda': 3.294655555198571e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.1420479678112752, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1420479678112752
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.8253145776720059, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8253145776720059
[LightGBM] [Warning] bagging_freq is set=90, subsample_freq=0 will be ignored. Current value: bagging_freq=90
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[466]	valid_0's huber: 3.06685
[I 2021-07-30 10:51:29,525] Finished trial#89 with value: 3.822946932883324 with parameters: {'objective': 'huber', 'learning_rate': 0.03929240481720371, 'n_estimators': 466, 'max_depth': 9, 'num_leaves': 12929, 'max_bin': 183, 'feature_fraction': 0.8253145776720059, 'bagging_fraction': 0.1420479678112752, 'bagging_freq': 90, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 0.0089218896931886, 'reg_lambda': 1.587006968166306e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9173756318825914, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9173756318825914
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.7378346939704971, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7378346939704971
[LightGBM] [Warning] bagging_freq is set=93, subsample_freq=0 will be ignored. Current value: bagging_freq=93
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[443]	valid_0's huber: 3.03916
[I 2021-07-30 10:52:05,923] Finished trial#90 with value: 3.793257165030105 with parameters: {'objective': 'huber', 'learning_rate': 0.04999176478170328, 'n_estimators': 1136, 'max_depth': 10, 'num_leaves': 22021, 'max_bin': 136, 'feature_fraction': 0.7378346939704971, 'bagging_fraction': 0.9173756318825914, 'bagging_freq': 93, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.016823554313916217, 'reg_lambda': 3.455555082520619e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9513112020948438, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9513112020948438
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8677874431388497, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8677874431388497
[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[235]	valid_0's huber: 3.03728
[I 2021-07-30 10:52:21,734] Finished trial#91 with value: 3.7915252802910127 with parameters: {'objective': 'huber', 'learning_rate': 0.09042709018136956, 'n_estimators': 940, 'max_depth': 9, 'num_leaves': 9770, 'max_bin': 158, 'feature_fraction': 0.8677874431388497, 'bagging_fraction': 0.9513112020948438, 'bagging_freq': 97, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.09815855461262696, 'reg_lambda': 5.606773773763761e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.8831496839548244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8831496839548244
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.884880434219223, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.884880434219223
[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[298]	valid_0's huber: 3.03516
[I 2021-07-30 10:52:34,832] Finished trial#92 with value: 3.789043441706853 with parameters: {'objective': 'huber', 'learning_rate': 0.0727096365043061, 'n_estimators': 952, 'max_depth': 8, 'num_leaves': 4940, 'max_bin': 206, 'feature_fraction': 0.884880434219223, 'bagging_fraction': 0.8831496839548244, 'bagging_freq': 100, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.08634747344711431, 'reg_lambda': 0.00018201154096434191}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9495236024098711, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9495236024098711
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.8109979990102993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8109979990102993
[LightGBM] [Warning] bagging_freq is set=94, subsample_freq=0 will be ignored. Current value: bagging_freq=94
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[222]	valid_0's huber: 3.02739
[I 2021-07-30 10:52:56,068] Finished trial#93 with value: 3.7799647553908056 with parameters: {'objective': 'huber', 'learning_rate': 0.0991561404225243, 'n_estimators': 1445, 'max_depth': 10, 'num_leaves': 16563, 'max_bin': 164, 'feature_fraction': 0.8109979990102993, 'bagging_fraction': 0.9495236024098711, 'bagging_freq': 94, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.05800287210700866, 'reg_lambda': 1.8614018050674082e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9097281237112669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9097281237112669
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.9080554130463953, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9080554130463953
[LightGBM] [Warning] bagging_freq is set=91, subsample_freq=0 will be ignored. Current value: bagging_freq=91
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[346]	valid_0's huber: 3.03214
[I 2021-07-30 10:53:17,401] Finished trial#94 with value: 3.785813288982351 with parameters: {'objective': 'huber', 'learning_rate': 0.06042628699167887, 'n_estimators': 1645, 'max_depth': 9, 'num_leaves': 1744, 'max_bin': 147, 'feature_fraction': 0.9080554130463953, 'bagging_fraction': 0.9097281237112669, 'bagging_freq': 91, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.03384980341256224, 'reg_lambda': 4.667352576779676e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9270920734371222, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9270920734371222
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.9706128471644322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9706128471644322
[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[284]	valid_0's huber: 3.03516
[I 2021-07-30 10:53:43,017] Finished trial#95 with value: 3.7886251423737853 with parameters: {'objective': 'huber', 'learning_rate': 0.07731470145281284, 'n_estimators': 805, 'max_depth': 10, 'num_leaves': 42088, 'max_bin': 165, 'feature_fraction': 0.9706128471644322, 'bagging_fraction': 0.9270920734371222, 'bagging_freq': 97, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.07939766864617516, 'reg_lambda': 0.00011046586737225161}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.19956723553442435, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19956723553442435
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7
[LightGBM] [Warning] feature_fraction is set=0.8521325723809521, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8521325723809521
[LightGBM] [Warning] bagging_freq is set=84, subsample_freq=0 will be ignored. Current value: bagging_freq=84
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[461]	valid_0's huber: 3.05126
[I 2021-07-30 10:54:00,053] Finished trial#96 with value: 3.8066411418110353 with parameters: {'objective': 'huber', 'learning_rate': 0.04673025754986627, 'n_estimators': 1276, 'max_depth': 9, 'num_leaves': 12739, 'max_bin': 174, 'feature_fraction': 0.8521325723809521, 'bagging_fraction': 0.19956723553442435, 'bagging_freq': 84, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.06097928355300908, 'reg_lambda': 6.309624168039283e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.8249733586146225, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8249733586146225
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8
[LightGBM] [Warning] feature_fraction is set=0.9390346930097198, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9390346930097198
[LightGBM] [Warning] bagging_freq is set=89, subsample_freq=0 will be ignored. Current value: bagging_freq=89
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[17]	valid_0's l2: 67.6176
[I 2021-07-30 10:54:02,769] Finished trial#97 with value: 5.110945744136558 with parameters: {'objective': 'mse', 'learning_rate': 0.08708267871891076, 'n_estimators': 1032, 'max_depth': 7, 'num_leaves': 29505, 'max_bin': 141, 'feature_fraction': 0.9390346930097198, 'bagging_fraction': 0.8249733586146225, 'bagging_freq': 89, 'min_sum_hessian_in_leaf': 8, 'reg_alpha': 0.03992116248983425, 'reg_lambda': 2.8166145170218092e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.8568949857212825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8568949857212825
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6
[LightGBM] [Warning] feature_fraction is set=0.1554271715698745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1554271715698745
[LightGBM] [Warning] bagging_freq is set=95, subsample_freq=0 will be ignored. Current value: bagging_freq=95
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[312]	valid_0's huber: 3.31477
[I 2021-07-30 10:54:11,528] Finished trial#98 with value: 4.105619787787423 with parameters: {'objective': 'huber', 'learning_rate': 0.06543566269664516, 'n_estimators': 312, 'max_depth': 11, 'num_leaves': 91, 'max_bin': 180, 'feature_fraction': 0.1554271715698745, 'bagging_fraction': 0.8568949857212825, 'bagging_freq': 95, 'min_sum_hessian_in_leaf': 6, 'reg_alpha': 0.010130570427534825, 'reg_lambda': 3.7964996918740184e-05}. Best is trial#74 with value: 3.77433718350238.
[LightGBM] [Warning] bagging_fraction is set=0.9774080056859988, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9774080056859988
[LightGBM] [Warning] min_sum_hessian_in_leaf is set=9, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=9
[LightGBM] [Warning] feature_fraction is set=0.7718370636359193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7718370636359193
[LightGBM] [Warning] bagging_freq is set=80, subsample_freq=0 will be ignored. Current value: bagging_freq=80
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[869]	valid_0's huber: 3.02977
[I 2021-07-30 10:54:44,770] Finished trial#99 with value: 3.7824957793551364 with parameters: {'objective': 'huber', 'learning_rate': 0.026357574159123112, 'n_estimators': 1131, 'max_depth': 8, 'num_leaves': 53113, 'max_bin': 155, 'feature_fraction': 0.7718370636359193, 'bagging_fraction': 0.9774080056859988, 'bagging_freq': 80, 'min_sum_hessian_in_leaf': 9, 'reg_alpha': 0.022807270141723804, 'reg_lambda': 0.0002202335861114443}. Best is trial#74 with value: 3.77433718350238.
Time consumed (min): 102.9
Best trial: 
{'objective': 'huber', 'learning_rate': 0.04153405228128592, 'n_estimators': 1074, 'max_depth': 8, 'num_leaves': 21473, 'max_bin': 187, 'feature_fraction': 0.7866249424381657, 'bagging_fraction': 0.8835990951694892, 'bagging_freq': 93, 'min_sum_hessian_in_leaf': 7, 'reg_alpha': 0.099327837369119, 'reg_lambda': 1.737834771403329e-05}
